'''Collection of reusable helper functions refactored from EDA notebooks.'''

# Standard library imports
from itertools import product

# PyPI imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from scipy import stats

def get_correlations(features_list: list, df: pd.DataFrame) -> pd.DataFrame:
    '''Takes list of string column names and a dataframe, calculates Pearson 
    correlation coefficient and Spearman rank correlation coefficient using
    SciPy. Returns a data frame with the results.'''

    # Dictionary to hold results, will be converted to a Pandas dataframe
    # at the end
    correlations={
        'Feature 1':[],
        'Feature 2':[],
        'Spearman coefficient':[],
        'Spearman p-value':[],
        'Pearson coefficient':[],
        'Pearson p-value':[],
        'Pearson r-squared':[]
    }

    # Create a list of unique feature pair tuples from the input list
    feature_pairs=list(set(tuple(sorted(pair)) for pair in product(features_list, features_list)))

    # Loop on the feature pairs to calculate the corelation coefficients between each
    for feature_pair in feature_pairs:

        # Exclude self pairs
        if feature_pair[0] != feature_pair[1]:

            # Get data for this feature pair
            feature_pair_data=df[[*feature_pair]].dropna()

            # Get Pearson and Spearman correlation coefficients and their p-values
            pcc=stats.pearsonr(feature_pair_data.iloc[:,0], feature_pair_data.iloc[:,1])
            src=stats.spearmanr(feature_pair_data.iloc[:,0], feature_pair_data.iloc[:,1])

            # Collect the results
            correlations['Feature 1'].append(feature_pair[0])
            correlations['Feature 2'].append(feature_pair[1])
            correlations['Spearman coefficient'].append(src.statistic)
            correlations['Spearman p-value'].append(src.pvalue)
            correlations['Pearson coefficient'].append(pcc.statistic)
            correlations['Pearson p-value'].append(pcc.pvalue)
            correlations['Pearson r-squared'].append(pcc.statistic**2)

    return pd.DataFrame.from_dict(correlations)


def plot_correlations(data_df: pd.DataFrame, correlations_df: pd.DataFrame) -> None:
    '''Takes a Pandas dataframe of features and a correlation dataframe for some or
    all of those features generated by get_correlations(). Plots each feature pair
    as scatter with best fit line. Uses kurtosis cutoff to decide which axes to log.'''

    fig, axs=plt.subplots(3,5, figsize=(11,7))
    fig.suptitle('Feature cross-correlations')

    for ax, (_, row) in zip(axs.flat, correlations_df.iterrows()):

        # Linear regression to show on plot
        feature_pair_data=data_df[[row['Feature 1'], row['Feature 2']]].dropna()
        regression=stats.linregress(feature_pair_data.iloc[:,0], feature_pair_data.iloc[:,1])
        regression_x=np.linspace(min(feature_pair_data.iloc[:,0]),max(feature_pair_data.iloc[:,0]))
        regression_y=regression.slope*regression_x + regression.intercept

        # Draw scatter plot with regression line
        ax.scatter(data_df[row['Feature 1']], data_df[row['Feature 2']], s=0.2, color='black')
        ax.plot(regression_x, regression_y, color='red')
        ax.set_xlabel(row['Feature 1'])
        ax.set_ylabel(row['Feature 2'])

        if stats.kurtosis(data_df[row['Feature 1']].dropna()) > 40:
            ax.set_xscale('log')
        
        if stats.kurtosis(data_df[row['Feature 2']].dropna()) > 40:
            ax.set_yscale('log')

    fig.tight_layout()

    return fig